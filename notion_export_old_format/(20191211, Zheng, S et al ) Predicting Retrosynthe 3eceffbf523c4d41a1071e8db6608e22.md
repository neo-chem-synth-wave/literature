# (20191211, Zheng, S. et al.) Predicting Retrosynthetic Reactions using Self-corrected Transformer Neural Networks

Tags: single-step-retrosynthesis, template-free

## Publication Overview

| **Title:**  | Predicting Retrosynthetic Reactions using Self-corrected Transformer Neural Networks |
| --- | --- |
| **Authors:**  | Shuangjia Zheng, Jiahua Rao, Zhongyue Zhang, Jun Xu, Yuedong Yang |
| Publication Date**:**  | 2019/12/11 |
| Publication Links: | [**ACS JCIM**](https://pubs.acs.org/doi/10.1021/acs.jcim.9b00949) |
| Alternative Links: | [**arXiv**](https://arxiv.org/abs/1907.01356) |
| Code Links: | [**Official GitHub Repository**](https://github.com/Jh-SYSU/SCROP) |

## Publication Abstract

<aside>
ℹ️ Synthesis planning is the process of recursively decomposing target molecules into available precursors. Computer-aided retrosynthesis can potentially assist chemists in designing synthetic routes; however, at present, it is cumbersome and cannot provide satisfactory results. In this study, we have developed a template-free self-corrected retrosynthesis predictor (SCROP) to predict retrosynthesis using transformer neural networks. In the method, the retrosynthesis planning was converted to a machine translation problem from the products to molecular linear notations of the reactants. By coupling with a neural network-based syntax corrector, our method achieved an accuracy of 59.0% on a standard benchmark data set, which outperformed other deep learning methods by >21% and template-based methods by >6%. More importantly, our method was 1.7 times more accurate than other state-of-the-art methods for compounds not appearing in the training set.

</aside>