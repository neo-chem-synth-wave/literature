# (20210111, Ucak, U.V. et al.) Substructure-based Neural Machine Translation for Retrosynthetic Prediction

Tags: single-step-retrosynthesis, template-free

## Publication Overview

| **Title:**  | Substructure-based Neural Machine Translation for Retrosynthetic Prediction |
| --- | --- |
| **Authors:**  | Umit V. Ucak, Taek Kang, Junsu Ko, Juyong Lee |
| Publication Date**:**  | 2021/01/11 |
| Publication Links: | [**BMC Journal of Cheminformatics**](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00482-z) |
| Alternative Links: | [**ChemRxiv](https://chemrxiv.org/engage/chemrxiv/article-details/60c74ea0f96a00c432287b14) | [ResearchGate](https://www.researchgate.net/publication/348399059_Substructure-based_neural_machine_translation_for_retrosynthetic_prediction)** |
| Code Links: | [**Official GitHub Repository**](https://github.com/knu-chem-lcbc/fragment_based_retrosynthesis) |

## Publication Abstract

<aside>
ℹ️ With the rapid improvement of machine translation approaches, neural machine translation has started to play an important role in retrosynthesis planning, which finds reasonable synthetic pathways for a target molecule. Previous studies showed that utilizing the sequence-to-sequence frameworks of neural machine translation is a promising approach to tackle the retrosynthetic planning problem. In this work, we recast the retrosynthetic planning problem as a language translation problem using a template-free sequence-to-sequence model. The model is trained in an end-to-end and a fully data-driven fashion. Unlike previous models translating the SMILES strings of reactants and products, we introduced a new way of representing a chemical reaction based on molecular fragments. It is demonstrated that the new approach yields better prediction results than current state-of-the-art computational methods. The new approach resolves the major drawbacks of existing retrosynthetic methods such as generating invalid SMILES strings. Specifically, our approach predicts highly similar reactant molecules with an accuracy of 57.7%. In addition, our method yields more robust predictions than existing methods.

</aside>