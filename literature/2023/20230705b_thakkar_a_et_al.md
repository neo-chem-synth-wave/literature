# Overview
**Title:**
Unbiasing Retrosynthesis Language Models With Disconnection Prompts

**Authors:**
Thakkar, A., Vaucher, A.C., Byekwaso, A., Schwaller, P., Toniato, A., and Laino, T. |
Thakkar, A. et al.

**Publication Date:**
2023/07/05

**Link:**
[ACS Central Science](https://pubs.acs.org/doi/10.1021/acscentsci.3c00372)

**Alternative Links:**
[ChemRxiv](https://chemrxiv.org/engage/chemrxiv/article-details/6328d0b8ba8a6d04fc551df7) |
[GitHub](https://github.com/rxn4chemistry/disconnection_aware_retrosynthesis) |
[PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC10390024) |
[ResearchGate](https://www.researchgate.net/publication/363673928_Unbiasing_Retrosynthesis_Language_Models_with_Disconnection_Prompts)

**Tags:**
single-step-retrosynthesis, template-free, optimization


# Abstract
Data-driven approaches to retrosynthesis are limited in user interaction, diversity of their predictions, and recommendation of unintuitive disconnection strategies.
Herein, we extend the notions of prompt-based inference in natural language processing to the task of chemical language modeling.
We show that by using a prompt describing the disconnection site in a molecule we can steer the model to propose a broader set of precursors, thereby overcoming training data biases in retrosynthetic recommendations and achieving a 39% performance improvement over the baseline.
For the first time, the use of a disconnection prompt empowers chemists by giving them greater control over the disconnection predictions, which results in more diverse and creative recommendations.
In addition, in place of a human-in-the-loop strategy, we propose a two-stage schema consisting of automatic identification of disconnection sites, followed by prediction of reactant sets, thereby achieving a considerable improvement in class diversity compared with the baseline.
The approach is effective in mitigating prediction biases derived from training data.
This provides a wider variety of usable building blocks and improves the end userâ€™s digital experience.
We demonstrate its application to different chemistry domains, from traditional to enzymatic reactions, in which substrate specificity is critical.


# Citation
```
@article {20230705b_thakkar_a_et_al,
  author       = { Amol Thakkar and Alain C. Vaucher and Andrea Byekwaso and Philippe Schwaller and Alessandra Toniato and Teodoro Laino },
  title        = { Unbiasing Retrosynthesis Language Models with Disconnection Prompts },
  journal      = { ACS Central Science },
  year         = { 2023 },
  pages        = { 1488-1498 },
  volume       = { 9 },
  number       = { 7 },
  doi          = { 10.1021/acscentsci.3c00372 },
  url          = { https://doi.org/10.1021/acscentsci.3c00372 },
  eprint       = { https://doi.org/10.1021/acscentsci.3c00372 }
}
```
