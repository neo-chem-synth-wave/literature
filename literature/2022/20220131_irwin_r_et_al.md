# Overview
**Title:**
Chemformer: A Pre-trained Transformer for Computational Chemistry

**Authors:**
Irwin, R., Dimitriadis, S., He, J., and Bjerrum, E.J. |
Irwin, R. et al.

**Publication Date:**
2022/01/31

**Link:**
[IOPscience Machine Learning: Science and Technology](https://iopscience.iop.org/article/10.1088/2632-2153/ac3ffb)

**Alternative Links:**
[ChemRxiv](https://chemrxiv.org/engage/chemrxiv/article-details/60ee8a3eb95bdd06d062074b) |
[GitHub](https://github.com/MolecularAI/Chemformer) |
[ResearchGate](https://www.researchgate.net/publication/356865938_Chemformer_A_Pre-Trained_Transformer_for_Computational_Chemistry)

**Starred:**
False

**Tags:**
single-step-retrosynthesis, multi-step-retrosynthesis, template-free, chemformer


# Abstract
Transformer models coupled with a simplified molecular line entry system (SMILES) have recently proven to be a powerful combination for solving challenges in cheminformatics.
These models, however, are often developed specifically for a single application and can be very resource-intensive to train.
In this work we present the Chemformer modelâ€”a Transformer-based model which can be quickly applied to both sequence-to-sequence and discriminative cheminformatics tasks.
Additionally, we show that self-supervised pre-training can improve performance and significantly speed up convergence on downstream tasks.
On direct synthesis and retrosynthesis prediction benchmark datasets we publish state-of-the-art results for top-1 accuracy.
We also improve on existing approaches for a molecular optimisation task and show that Chemformer can optimise on multiple discriminative tasks simultaneously.
Models, datasets and code will be made available after publication.


# Citation
```
@article {irwin2022a,
  author       = { Ross Irwin and Spyridon Dimitriadis and Jiazhen He and Esben Jannik Bjerrum },
  title        = { Chemformer: a pre-trained transformer for computational chemistry },
  journal      = { Machine Learning: Science and Technology },
  year         = { 2022 },
  pages        = { 015022 },
  month        = { Jan },
  volume       = { 3 },
  number       = { 1 },
  doi          = { 10.1088/2632-2153/ac3ffb },
  url          = { https://dx.doi.org/10.1088/2632-2153/ac3ffb },
  publisher    = { IOP Publishing }
}
```
